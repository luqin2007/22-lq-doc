LangChain 支持三种模型：
- 大语言模型 LLM：输入文本，返回字符串
	- OpenAI，豆包，星火等在线大模型，可参考[此处](https://python.langchain.ac.cn/docs/integrations/llms/)接入
	- 在 [HuggingFace](https://huggingface.co/) 下载预训练模型，微调后使用，如 Llama2。使用 `HuggingFaceHub` 或 `HuggingFacePipeline`
- 聊天模型 Chat Model：基于 LLM 但更结构化，支持将聊天消息列表作为输入
- 文本嵌入模型 Embedding Model：用于文本嵌入，将文本存入
## 预训练模型

> [!note] 预训练模型：通过 `Transformer` 等架构初步学习词汇、语法、句子结构和上下文信息等语言知识后的模型

可使用 HuggingFace 下载预训练模型并进行微调，需要申请 `HuggingFace` Token 并安装 `transformers` 库
- [ ] 模型微调细节

> [!note] 模型量化：简化模型权重，以减少模型大小和计算需求，量化后的模型常以 GGML 或 GPTQ 结尾
## 自定义模型

创建类继承自 `LLM`，实现 `_call` 方法即可
- `_call(self, prompt: str, stop: Optional[List[str]]) -> str`：接收输入字符串并返回响应字符串
- `_identifying_params(self)`：可选，输出模型信息